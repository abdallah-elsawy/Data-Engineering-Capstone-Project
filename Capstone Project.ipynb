{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Climate change and Immigration\n",
    "\n",
    "#### Project Summary\n",
    "Today, 1% of the world is a barely livable hot zone.By 2070, that portion could go up to 19%.Billions of people call this land home.\n",
    "Where will they go? we will help the countries and governments to understand the bisc relation between the climate change and the immigration issue.\n",
    "\n",
    "The project follows the follow steps:\n",
    "    \n",
    "<li><a href=\"#s1\">Step 1: Scope the Project and Gather Data</a>\n",
    "<li><a href=\"#s2\">Step 2: Explore and Assess the Data</a>\n",
    "<li><a href=\"#s3\">Step 3: Define the Data Model</a>\n",
    "<li><a href=\"#s4\">Step 4: Run ETL to Model the Data</a>\n",
    "<li><a href=\"#s5\">Step 5: Complete Project Write Up</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## </h3> Step 1: Scope the Project and Gather Data</h3><a id=\"s1\"></a>\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "In this project we will use  some important datasets related to immigration process and the temperature with the world. We will use some usful data enginnering tools like data werehouses,AWS  S3,  Spark, Apache Airflow and AWS Warehouse like Redshif\n",
    "#### Describe and Gather Data \n",
    "\n",
    "- 1- I94 Immigration dataset: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace.  [This](https://www.trade.gov/national-travel-and-tourism-office) is where the data comes from. \n",
    "\n",
    "- 2- World Temperature dataset: This dataset came from Kaggle. You can read more about it [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#all imports and installs\n",
    "import pandas as pd\n",
    "import os\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "# df_spark.write.parquet(\"sas_data\")\n",
    "# df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I94 Immigration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat' \n",
    "df_immigration = spark.read.format('com.github.saurfang.sas.spark').load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247104e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247140e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247161e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247080e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20562.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247849e+10</td>\n",
       "      <td>00608</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "5   18.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MI   \n",
       "6   19.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "7   20.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "8   21.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "9   22.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "5  20555.0   ...        None        M   1959.0  09302016   None   None   \n",
       "6  20558.0   ...        None        M   1953.0  09302016   None   None   \n",
       "7  20558.0   ...        None        M   1959.0  09302016   None   None   \n",
       "8  20553.0   ...        None        M   1970.0  09302016   None   None   \n",
       "9  20562.0   ...        None        M   1968.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "5      AZ  9.247104e+10  00602       B1  \n",
       "6      AZ  9.247140e+10  00602       B2  \n",
       "7      AZ  9.247161e+10  00602       B2  \n",
       "8      AZ  9.247080e+10  00602       B2  \n",
       "9      AZ  9.247849e+10  00608       B1  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_immigration.show(n=10)\n",
    "df_immigration.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### World Temperature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file_name = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = spark.read.csv(file_name, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-04-01 00:00:00|5.7879999999999985|           3.6239999999999997|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-05-01 00:00:00|            10.644|           1.2830000000000001|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-06-01 00:00:00|14.050999999999998|                        1.347|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-07-01 00:00:00|            16.082|                        1.396|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-08-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temperature.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <h3> Step 2: Explore and Assess the Data </h3><a id=\"s2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- I94 Immigration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop duplicate rows\n",
    "df_immigration_new = df_immigration.dropDuplicates(['cicid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_new.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "it seems that no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "immigration = pd.read_sas(immigration_fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cicid             0\n",
       "i94yr             0\n",
       "i94mon            0\n",
       "i94cit            0\n",
       "i94res            0\n",
       "i94port           0\n",
       "arrdate           0\n",
       "i94mode         239\n",
       "i94addr      152372\n",
       "depdate      142457\n",
       "i94bir          802\n",
       "i94visa           0\n",
       "count             0\n",
       "dtadfile          1\n",
       "visapost    1881250\n",
       "occup       3088187\n",
       "entdepa         238\n",
       "entdepd      138429\n",
       "entdepu     3095921\n",
       "matflag      138429\n",
       "biryear         802\n",
       "dtaddto         477\n",
       "gender       414269\n",
       "insnum      2982605\n",
       "airline       83627\n",
       "admnum            0\n",
       "fltno         19549\n",
       "visatype          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "we see that those columns (visapost ,insnum , occup, entdepu, ) have most of the missing values so we will remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols = ['visapost', 'insnum','occup', 'entdepu',]\n",
    "df_immigration_new = df_immigration_new.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all missing values for the rest of the dataeset\n",
    "df_immigration_new = df_immigration_new.dropna(how=\"any\", subset=[\"i94port\",\"airline\" ,\"i94addr\", \"gender\",\"fltno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2492563"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3096313 entries, 0 to 3096312\n",
      "Data columns (total 28 columns):\n",
      "cicid       float64\n",
      "i94yr       float64\n",
      "i94mon      float64\n",
      "i94cit      float64\n",
      "i94res      float64\n",
      "i94port     object\n",
      "arrdate     float64\n",
      "i94mode     float64\n",
      "i94addr     object\n",
      "depdate     float64\n",
      "i94bir      float64\n",
      "i94visa     float64\n",
      "count       float64\n",
      "dtadfile    object\n",
      "visapost    object\n",
      "occup       object\n",
      "entdepa     object\n",
      "entdepd     object\n",
      "entdepu     object\n",
      "matflag     object\n",
      "biryear     float64\n",
      "dtaddto     object\n",
      "gender      object\n",
      "insnum      object\n",
      "airline     object\n",
      "admnum      float64\n",
      "fltno       object\n",
      "visatype    object\n",
      "dtypes: float64(13), object(15)\n",
      "memory usage: 661.4+ MB\n"
     ]
    }
   ],
   "source": [
    "immigration.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "we see that the data column arrdate is a float so we should convert it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert date form SAS format to PySpark format\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "@udf(StringType())\n",
    "def convert_datetime(x):\n",
    "    if x:\n",
    "        return (datetime(1960, 1, 1).date() + timedelta(x)).isoformat()\n",
    "    return None\n",
    "\n",
    "df_immigration_new = df_immigration_new.withColumn(\"arrdate\", convert_datetime(df_immigration_new.arrdate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- World Temperature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temperature.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                    0\n",
       "AverageTemperature               364130\n",
       "AverageTemperatureUncertainty    364130\n",
       "City                                  0\n",
       "Country                               0\n",
       "Latitude                              0\n",
       "Longitude                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature = pd.read_csv(fname, sep=',')\n",
    "# check the missing values\n",
    "temperature.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the duplicates\n",
    "temperature.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove all missing values for the rest of the dataeset\n",
    "df_temperature_new = df_temperature.dropna(how=\"any\", subset=[\"AverageTemperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8235082"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature_new.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <h3> Step 3: Define the Data Model </h3><a id=\"s3\"></a>\n",
    "#### 3.1 Conceptual Data Model\n",
    "We will use the star schema data model because we could easily work on it by create and join tables.\n",
    "the following image indicates the star schema diagram:\n",
    "![](images/star_schema.png)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "the steps necessary to pipeline the data.\n",
    "\n",
    "- 1- Upload the data into the S3 Redshift.\n",
    "- 2- use Apache Airflow to perform the data pipelines.\n",
    "- 3- Load Fact Operator\n",
    "- 4- Data Quality check\n",
    "- 5- End dummy operator\n",
    "\n",
    "which will be found here [Airflow](https://r766466c839826xjupyterlnnfq3jud.udacity-student-workspaces.com/lab/tree/Airflow) folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " ## <h3> Step 4: Run Pipelines to Model the Data  </h3><a id=\"s4\"></a>\n",
    "#### 4.1 Create the data model\n",
    "we will find that here [Capstone Project](https://r766466c839826xjupyterlnnfq3jud.udacity-student-workspaces.com/lab/tree/Capstone%20Project.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "we will find that here [data_quality](https://r766466c839826xjupyterlnnfq3jud.udacity-student-workspaces.com/lab/tree/Airflow/plugins/operators/data_quality.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "- 1- I94 Immigration dataset: \n",
    "##### immigration\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Column Name</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">CICI </td><td class=\"tg-0pky\">Primary Key Unique ID</td></tr>\n",
    " <tr><td class=\"tg-0pky\">i94yr</td><td class=\"tg-0pky\"> year</td></tr>\n",
    " <tr><td class=\"tg-0pky\">i94mon</td><td class=\"tg-0pky\"> month</td></tr>\n",
    " <tr><td class=\"tg-0pky\">i94port</td><td class=\"tg-0pky\">Port of admission</td></tr>\n",
    " <tr><td class=\"tg-0pky\">arrdate</td><td class=\"tg-0pky\">Arrival Date</td></tr>\n",
    " <tr><td class=\"tg-0pky\">i94mode</td><td class=\"tg-0pky\">Mode of transportation</td></tr>\n",
    " <tr><td class=\"tg-0pky\">i94addr</td><td class=\"tg-0pky\">USA State of arrival</td></tr>\n",
    " <tr><td class=\"tg-0pky\">depdate</td><td class=\"tg-0pky\">Departure Date </td></tr>\n",
    " <tr><td class=\"tg-0pky\">i94bir</td><td class=\"tg-0pky\">Age of birth</td></tr>\n",
    " <tr><td class=\"tg-0pky\">i94visa</td><td class=\"tg-0pky\">Visa codes </td></tr>\n",
    " <tr><td class=\"tg-0pky\">count</td><td class=\"tg-0pky\">count</td></tr>\n",
    " <tr><td class=\"tg-0pky\">dtadfile</td><td class=\"tg-0pky\">Character string </td></tr>\n",
    " <tr><td class=\"tg-0pky\">visapost</td><td class=\"tg-0pky\">Department of State</td></tr>\n",
    " <tr><td class=\"tg-0pky\">occup</td><td class=\"tg-0pky\">Occupation </td></tr>\n",
    " <tr><td class=\"tg-0pky\">entdepa</td><td class=\"tg-0pky\">Arrival Flag </td></tr>\n",
    " <tr><td class=\"tg-0pky\">entdepd</td><td class=\"tg-0pky\">Departure Flag </td></tr>\n",
    " <tr><td class=\"tg-0pky\">entdepu</td><td class=\"tg-0pky\">Update Flag </td></tr>\n",
    " <tr><td class=\"tg-0pky\">matflag</td><td class=\"tg-0pky\">Match flag </td></tr>\n",
    " <tr><td class=\"tg-0pky\">biryear</td><td class=\"tg-0pky\">year of birth</td></tr>\n",
    " <tr><td class=\"tg-0pky\">visatype</td><td class=\"tg-0pky\">visa type</td></tr>\n",
    " <tr><td class=\"tg-0pky\">dtaddto</td><td class=\"tg-0pky\">how long stay</td></tr>\n",
    " <tr><td class=\"tg-0pky\">gender</td><td class=\"tg-0pky\">sex</td></tr>\n",
    " <tr><td class=\"tg-0pky\">airline</td><td class=\"tg-0pky\">airline</td></tr>\n",
    "</table>\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- 2- World Temperature dataset : Indicates Earth Surface Temperature Data, Exploring global temperatures since 1750.\n",
    "\n",
    "##### temperature\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Column Name</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">Code </td><td class=\"tg-0pky\">Country Code</td></tr>\n",
    " <tr><td class=\"tg-0pky\">Country</td><td class=\"tg-0pky\"> Country Name</td></tr>\n",
    " <tr><td class=\"tg-0pky\">AverageTemperature</td><td class=\"tg-0pky\"> Temperature of the country between 1743 and 2013</td></tr>\n",
    " <tr><td class=\"tg-0pky\">Latitude</td><td class=\"tg-0pky\">GPS coordinates</td></tr>\n",
    " <tr><td class=\"tg-0pky\">Longitude</td><td class=\"tg-0pky\">GPS coordinates</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## <h3> Step 5: Complete Project Write Up  </h3><a id=\"s5\"></a>\n",
    "### Tools and technologies for the project.\n",
    "     \n",
    "     - Spark\n",
    "     - AWS S3\n",
    "     - Apache Airflow \n",
    "     - AWS Warehouse like Redshift \n",
    "\n",
    "\n",
    "### How often the data should be updated and why.\n",
    "     \n",
    "     - Should be updated Monthly Should be updated Monthly because the data is formed monthly.\n",
    "     \n",
    "### How we will deal with those differently under the following scenarios:\n",
    "#### The data was increased by 100x.\n",
    "      - Use partitioning  of the data or use AWS EMR\n",
    "#### The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "      - We should use Apache Airflow  to updated dashboard daily.\n",
    "#### The database needed to be accessed by 100+ people.\n",
    "      - Use partitioning to give the ability to all users to access the data quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
